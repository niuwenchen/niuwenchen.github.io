<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="zh-CN">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="NLP," />










<meta name="description" content="Naive Bayes  and Sentiment Classification 贝叶斯是一个概率分类器，一个文本d，在所有类别C中，给出一个该文档属于某一个类别概率最大的类别。 $$ \widehat{c}=\underset{c\in C}{armax}P(c|d)=\underset{c\in C}{armax}\frac{P(d|c)P(c)}{P(d)} $$ 化简该公式，P(d)概率">
<meta name="keywords" content="NLP">
<meta property="og:type" content="article">
<meta property="og:title" content="6 Naive Bayes Classification and Sentiment">
<meta property="og:url" content="http://niuwenchen.github.io/2018/01/18/6-Naive-Bayes-Classification-and-Sentiment/index.html">
<meta property="og:site_name" content="SpeechAndLanguageProcessing">
<meta property="og:description" content="Naive Bayes  and Sentiment Classification 贝叶斯是一个概率分类器，一个文本d，在所有类别C中，给出一个该文档属于某一个类别概率最大的类别。 $$ \widehat{c}=\underset{c\in C}{armax}P(c|d)=\underset{c\in C}{armax}\frac{P(d|c)P(c)}{P(d)} $$ 化简该公式，P(d)概率">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="http://niuwenchen.github.io/img/nlp6_1.png">
<meta property="og:image" content="http://niuwenchen.github.io/img/nlp6_2.png">
<meta property="og:image" content="http://niuwenchen.github.io/img/nlp6_3.png">
<meta property="og:image" content="http://niuwenchen.github.io/img/nlp6_4.png">
<meta property="og:image" content="http://niuwenchen.github.io/img/nlp6_5.png">
<meta property="og:image" content="http://niuwenchen.github.io/img/nlp6_6.png">
<meta property="og:image" content="http://niuwenchen.github.io/img/nlp6_7.png">
<meta property="og:updated_time" content="2018-01-23T12:23:18.135Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="6 Naive Bayes Classification and Sentiment">
<meta name="twitter:description" content="Naive Bayes  and Sentiment Classification 贝叶斯是一个概率分类器，一个文本d，在所有类别C中，给出一个该文档属于某一个类别概率最大的类别。 $$ \widehat{c}=\underset{c\in C}{armax}P(c|d)=\underset{c\in C}{armax}\frac{P(d|c)P(c)}{P(d)} $$ 化简该公式，P(d)概率">
<meta name="twitter:image" content="http://niuwenchen.github.io/img/nlp6_1.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://niuwenchen.github.io/2018/01/18/6-Naive-Bayes-Classification-and-Sentiment/"/>





  <title>6 Naive Bayes Classification and Sentiment | SpeechAndLanguageProcessing</title><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">

  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">SpeechAndLanguageProcessing</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">translate and learning language model</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Startseite
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archiv
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://niuwenchen.github.io/2018/01/18/6-Naive-Bayes-Classification-and-Sentiment/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="JackNiu">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="SpeechAndLanguageProcessing">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">6 Naive Bayes Classification and Sentiment</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Veröffentlicht am</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-01-18T16:44:48+08:00">
                2018-01-18
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h2>Naive Bayes  and Sentiment Classification</h2>
<p>贝叶斯是一个概率分类器，一个文本d，在所有类别C中，给出一个该文档属于某一个类别概率最大的类别。</p>
<p>$$ \widehat{c}=\underset{c\in C}{armax}P(c|d)=\underset{c\in C}{armax}\frac{P(d|c)P(c)}{P(d)} $$</p>
<p>化简该公式，P(d)概率对于每一个类都是一样的，对同一个文档d计算其最大概率，因此P(d)是一样的。</p>
<p>计算$\hat{c}$的过程: prior probabilities(先验概率)，P(d|c)的似然概率。</p>
<p>$$\widehat{c}=\underset{c\in C}{armax}\overset{likelihood}{P(d|c)}\overset{prior}{P(c)}$$</p>
<p>一个文档可以用一系列特征来替代</p>
<p>$$\widehat{c}=\underset{c\in C}{armax}\overset{likelihood}{P(f1,f2,fn|c)}\overset{prior}{P(c)}$$</p>
<p>对于上面的等式，如果没有一些简化假设，无法计算（对于每一个单词和位置都有可能）。</p>
<p>第一种方式是BOW假设：不考虑位置，只关注单词，无论love这个单词出现在di1位或者第20位都有相同的意义或影响力。因此，假设特征f1,f2,...fn仅仅编码单词的id，不考虑位置。</p>
<p>第二种方式通常被称为贝叶斯假设： 条件独立性假设，$P(f_{i}|c)$独立分布，并且上面的计算公式可以被假设为以下:</p>
<p>$$P(f_{1},f_{2},f_{n}|c)=P(f_{1}|c)P(f_{2}|c)...P(f_{n}|c)$$</p>
<p>最后的公式可以如下:</p>
<p>$$c_{NB}=\underset{c\in C}{argmax}P(c)\prod P(f|c)$$</p>
<p>为了将NB分类器应用到文本中，需要考虑单词位置，简单的给文档中的每一个单词给一个下标</p>
<p>positions &lt;--all word positions in ttest document；</p>
<p>NB分类器计算方式是对数形式，避免underflow和increase speed,</p>
<p>$$c_{NB}=\underset{c\in C}{argmax}logP(c)+\sum_{i\in positions}P(w_{i}|c)$$</p>
<p>通过在对数空间中计算特征，上面等式将输入特征作为一个线性函数来预测类别。 分类似使用一个线性组合计算分类---类似NB和LR等---都被称为线性分类器。</p>
<p>也就是说: 贝叶斯分类器最后是一个线性分类器。</p>
<h2>训练贝叶斯分类器。</h2>
<p>计算先验概率$P(c)$，</p>
<p>$\hat{P(c)}=\frac{N_{c}}{N_{doc}}$。</p>
<p>计算条件概率$P(f_{i}|c)$</p>
<p>假设每一个在文档中的单词是一个特征，因此计算的是 $P(w_{i}|c)$,</p>
<p>计算在所有文档中单词$w_{i}$作为某一个类别c出现的次数，</p>
<p>$$\hat{P(w_{i}|c)}=\frac{count(w_{i},c)}{\sum_{w\in V} count(w,c)}$$</p>
<p>V是所有类别中出现的词汇，不仅仅是在类别c中出现的词汇。</p>
<pre><code>这里有个疑问? 类别1，计算类别1中单词w出现的次数，分母是确定的，分母是计算所有类别1中所有单词出现的次数，而不仅仅是特定的w。
</code></pre>
<p>还需要对这个公式做一些平滑处理，最简单的方式是add-one 平滑方法。</p>
<p>$$\hat{P(w_{i}|c)}=\frac{count(w_{i},c)+1}{(\sum_{w\in V} count(w,c))+|V|}$$</p>
<p>一些系统选择完全忽略一些单词的类别: stop words,非常常见的单词如the和a。将词汇表按照顺序排序，定义top10~100的单词为定用词，或者选择一些已经定义好的停用词。然后这些停用词将从训练集和测试集中删除。</p>
<h2>Worked example</h2>
<p><img src="/img/nlp6_1.png" alt=""></p>
<p>计算过程
<img src="/img/nlp6_2.png" alt=""></p>
<pre><code>计算P(w|c)出现一些疑惑？
计算count(w,c)
for d in document_of_c:	
	count(w,c) 这里的计数过程是统计每一个文档中该单词出现的次数，还是统计出现该单词的文档次数。
	目前暂定为出现的单词次数。
</code></pre>
<p>上面的数据P(-)=3/5=0.6; P(+)=2/5=0.4</p>
<pre><code>计算label为- 中的单词条件概率，
	总的词汇是20个，negative中出现的单词是14个，分母是count(w,c)=14，对于该类不变。分子变化
	predictable： 1次
	no: 1
	fun: 1
计算label为+中的条件概率
	总的词汇是20个，positive中为9个，分母为9保持不变
	predictable： 0次
	no: 0
	fun:1
</code></pre>
<p><img src="/img/nlp6_3.png" alt=""></p>
<p>$$P(-)P(S|-)=3/5\times 2/34 \times 2/34 \times 1/34 = 6.1 \times 10^{-5}$$
$$P(+)P(S|+)=2/5\times 1/29 \times 1/29 \times 2/29 = 3.2 \times 10^{-5}$$</p>
<p>因此这个模型预测这个句子是class negative。</p>
<pre><code>从上面的计算过程可以看出，贝叶斯分类器实际上根本不用训练分类器，只是将测试数据
和训练数据用某种方式计算概率即可。
根据类别的定义，实际上在计算过程中，训练语料的先验概率，似然值中属于某一个类的
分母都是确定的，只是分子不同而已。
但是在这个例子中还是没有说明对于句子中出现相同词的计算方式，现在就按照词的次数
进行计算，如果在一个文档中出现多次，那就累加多次。
</code></pre>
<h2>Optimizing for Sentiment Analysis</h2>
<p>情感分类器中，一个单词是否出现的影响力远远高于它出现的频率。因此在情感分类器中，通过对一个文档中进行单词去重。</p>
<p><img src="/img/nlp6_4.png" alt=""></p>
<p>第一种方式是单词去重，对于情感分析而言，只要其出现就行，不要求数量</p>
<p>另一种方式是对于negation样本的处理。</p>
<pre><code>I really like this movie 
I didn't like this movie
</code></pre>
<p>负样本通过一个didn't 完全的将整个语境改变。因此，负样本完全可以通过修改一个单词使该样本变成正样本。</p>
<p>一种非常简单的方法在情绪分析中是将negation中的单词全部加上NOT_前缀，</p>
<pre><code>didn't like this movie, but I
didn't NOT_like NOT_this NOT_movie, but I
</code></pre>
<p>新形式大单词像NOT_like ,NOT_recommend 将会在负样本中出现多次，并且是negative情绪的关键指示，但是像NOT_bored,NOT_dismiss 将会表现为positive情绪。</p>
<p>sentiment lexicons（情绪字典），General Inquirer，LIWC，MPQA。</p>
<p>MPQA字典有6885个单词，2718个正例，4912个反例。</p>
<pre><code>+: admirable,beautiful,condident,dazzling,ecstatic,favor,glee,great
-: awful,bad,bias,catastroph,cheat,deny,envious,foul,harsh,hate
</code></pre>
<p>18章将会介绍如何自动分类这些单词。</p>
<h2>Naive Bayes as a Language Model</h2>
<p>贝叶斯分类可以使用任何特征:字典，url，email，网络特征，短语，解析树等等。但是如果按照前面介绍的，仅使用独立的单词特征，使用在文档中的所有特征，贝叶斯分类器和LM模型很相似。特别的，一个贝叶斯分类器可以被看作一个限定类别的unigram 语言模型，对于每一个类别而言都会生成一个语言模型</p>
<p>对于每一个单词,概率 P(word|c), 这个模型也会对每一个句子赋予一个概率</p>
<p>$$P(s|c)=\prod <em>{i \in sentence} P(w</em>{i}|c)$$</p>
<p><img src="/img/nlp6_5.png" alt=""></p>
<pre><code>P(&quot;I love this fun film&quot;|+)= 0.1*0.1*0.01*0.05*0.1 = 0.0000005
P(&quot;I love this fun film&quot;|-)=...=0.0000000010

P(s|pos) &gt;P(s|neg).
</code></pre>
<h2>Evaluation:Precision,Recall,F-measure</h2>
<p><img src="/img/nlp6_6.png" alt=""></p>
<p>accuracy有局限，很简单的例子，</p>
<pre><code>假如100万封邮件，只有100封邮件在表达喜欢或讨厌
假设一个分类器将所有的邮件都标成&quot;不谈论公司&quot;。这个分类器将会有999900个正确的分类并且只有
100个错误分类，那么准确率是99.99%。
准确率很高，但是实际上这个分类器是无效的。
准确性度量指标对于发现一些特殊的，或者不均衡的样本来说不是最好的、
Precision: 度量系统认为正样本中，被判断准确的概率（以系统为衡量基准）
</code></pre>
<p>$$Precision = \frac{true \ positives}{true \ positiive + false\ positives}$$</p>
<pre><code>Recall: measures the percentage of items actually present in the input that were identified by the system
度量所有正样本被判断准确的概率，（以原始数据为衡量基准）
</code></pre>
<p>$$Recall = \frac{true \ positives}{true \ positiive + false\ negatives}$$</p>
<p>实际中，将Precision和Recall结合起来使用，F-measure</p>
<p>$$F_{\beta } =\frac{(\beta ^2+1)PR}{\beta ^2P+R}$$</p>
<p>F-measure度量有个倾向性，$\beta &gt;1$ 倾向于recall，小于1 倾向于precision，相等的话则两者均衡。F1度量方式。</p>
<p>$$F_{1} = \frac{2PR}{P+R}$$</p>
<h2>More than two classes</h2>
<h2>Test sets and Cross-validation</h2>
<p>用training训练模型，用devset调整参数，用test生成性能报告。</p>
<p>cv: 随机选择训练集和测试集，训练模型，然后计算错误率。然后重复随机选择数据。重复10次会得到10次错误率， 10折交叉验证法。</p>
<p><img src="/img/nlp6_7.png" alt=""></p>
<h2>Statistical Significance Testing(统计显著性检验)</h2>
<h2>总结</h2>
<p>介绍贝叶斯分类器，在情绪分类中使用。</p>
<ul>
<li>Many language processing tasks can be viewed as tasks of classification. learn to model the class given the observation</li>
<li>Text categorization,in which an entire text is assigned a class from a finite set, comprises such tasks as sentiment analysis,spam detection,email classification,and authorship attribution.</li>
<li>Sentiment analyssis classifis a text as reflecting the positive or negative orientation that a weiter expresses toward some object</li>
<li>Naive Bayes is a generative model that make the bag of words assumption and conditional independence assumption</li>
<li>Naive Bayes with binarized features seems to work better for many text classificatoin tasks</li>
</ul>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/NLP/" rel="tag"># NLP</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2018/01/18/5-Spelling-Correction-and-the-Noisy-Channel/" rel="next" title="5 Spelling Correction and the Noisy Channel">
                <i class="fa fa-chevron-left"></i> 5 Spelling Correction and the Noisy Channel
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2018/01/20/HMM/" rel="prev" title="HMM">
                HMM <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Inhaltsverzeichnis
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Übersicht
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">JackNiu</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">30</span>
                  <span class="site-state-item-name">Artikel</span>
                </a>
              </div>
            

            

            
              
              
              <div class="site-state-item site-state-tags">
                
                  <span class="site-state-item-count">10</span>
                  <span class="site-state-item-name">Tags</span>
                
              </div>
            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#undefined"><span class="nav-number">1.</span> <span class="nav-text">Naive Bayes  and Sentiment Classification</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#undefined"><span class="nav-number">2.</span> <span class="nav-text">训练贝叶斯分类器。</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#undefined"><span class="nav-number">3.</span> <span class="nav-text">Worked example</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#undefined"><span class="nav-number">4.</span> <span class="nav-text">Optimizing for Sentiment Analysis</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#undefined"><span class="nav-number">5.</span> <span class="nav-text">Naive Bayes as a Language Model</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#undefined"><span class="nav-number">6.</span> <span class="nav-text">Evaluation:Precision,Recall,F-measure</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#undefined"><span class="nav-number">7.</span> <span class="nav-text">More than two classes</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#undefined"><span class="nav-number">8.</span> <span class="nav-text">Test sets and Cross-validation</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#undefined"><span class="nav-number">9.</span> <span class="nav-text">Statistical Significance Testing(统计显著性检验)</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#undefined"><span class="nav-number">10.</span> <span class="nav-text">总结</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">JackNiu</span>

  
</div>


  <div class="powered-by">Erstellt mit  <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Muse</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config("");
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="custom_mathjax_source">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->
  


  

  

</body>
</html>
